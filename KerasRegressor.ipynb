{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KerasRegressor.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP5N+mJCy//sSzz1sKrED5R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DGuilherme/TurbofanVibration/blob/master/KerasRegressor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Flx-HKV_EaMG"
      },
      "source": [
        "# Keras Regressor \r\n",
        "\r\n",
        "\r\n",
        "*usefull links*  \r\n",
        "* [Adam](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)\r\n",
        "+ [Keras Regressor](https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIOgrrBkExzR"
      },
      "source": [
        "# Use seaborn for pairplot\r\n",
        "!pip install -q seaborn"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSPhPOm7ETf0"
      },
      "source": [
        "# imports\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras.layers.experimental import preprocessing\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "# random forests\r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "from sklearn.metrics import mean_squared_error,accuracy_score,r2_score,mean_absolute_error\r\n",
        "\r\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6_lPTLVE3Gl"
      },
      "source": [
        "# Make numpy printouts easier to read.\r\n",
        "np.set_printoptions(precision=3, suppress=True)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYPoWKgHE5pI"
      },
      "source": [
        "# Load the data\r\n",
        "\r\n",
        "###################\r\n",
        "#      TRAIN      #\r\n",
        "###################\r\n",
        "\r\n",
        "url = 'https://raw.githubusercontent.com/DGuilherme/TurbofanVibration/master/Dataset/ALLtrainMescla5D.csv'\r\n",
        "train_data = pd.read_csv(url,delimiter=r\",\")\r\n",
        "#print(train_data)\r\n",
        "\r\n",
        "model_mapping  ={'model1': 1, 'model2': 2, 'model3': 3, 'model4': 4}\r\n",
        "train_data = train_data.replace({'model': model_mapping})\r\n",
        "\r\n",
        "failure_mapping = {'none': 0, 'comp1': 1, 'comp2': 2, 'comp3': 3, 'comp4': 4}\r\n",
        "train_data = train_data.replace({'failure': failure_mapping})\r\n",
        "\r\n",
        "# remover colunas\r\n",
        "train_data = train_data.drop('datetime',axis=1)\r\n",
        "train_data = train_data.astype('float32')\r\n",
        "\r\n",
        "\r\n",
        "n_features = 31\r\n",
        "n_target = 35\r\n",
        "target = 'RUL_I'\r\n",
        "\r\n",
        "feature_list = [train_data.columns[i] for i in range(0,n_features)]\r\n",
        "\r\n",
        "X_train = train_data.iloc[:, 0:n_features].values.astype('float32')\r\n",
        "\r\n",
        "# generate labels\r\n",
        "Y_train = train_data.iloc[:, n_target-1:n_target].values.astype('float32').ravel()\r\n",
        "\r\n",
        "###################\r\n",
        "#      TEST       #\r\n",
        "###################\r\n",
        "\r\n",
        "#https://raw.githubusercontent.com/DGuilherme/TurbofanVibration/master/Dataset/ALLtrainMescla5D.csv\r\n",
        "\r\n",
        "url = 'https://raw.githubusercontent.com/DGuilherme/TurbofanVibration/master/Dataset/ALLtrainMescla5D.csv'\r\n",
        "test_data = pd.read_csv(url,delimiter=r\",\")\r\n",
        "\r\n",
        "model_mapping  ={'model1': 1, 'model2': 2, 'model3': 3, 'model4': 4}\r\n",
        "test_data = test_data.replace({'model': model_mapping})\r\n",
        "\r\n",
        "failure_mapping = {'none': 0, 'comp1': 1, 'comp2': 2, 'comp3': 3, 'comp4': 4}\r\n",
        "test_data = test_data.replace({'failure': failure_mapping})\r\n",
        "\r\n",
        "# remover colunas\r\n",
        "test_data = test_data.drop('datetime',axis=1)\r\n",
        "test_data = test_data.astype('float32')\r\n",
        "\r\n",
        "\r\n",
        "X_test = test_data.iloc[:, 0:n_features].values.astype('float32')\r\n",
        "# generate labels\r\n",
        "Y_test = test_data.iloc[:, n_target-1:n_target].values.astype('float32').ravel()\r\n",
        "\r\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa6K2w5-FXBz"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "\r\n",
        "num_cols = train_data.columns[train_data.dtypes.apply(lambda c: np.issubdtype(c, np.number))]\r\n",
        "\r\n",
        "trans = MinMaxScaler()\r\n",
        "# normaliza train\r\n",
        "train_data[num_cols] = trans.fit_transform(train_data[num_cols])\r\n",
        "\r\n",
        "#normaliza test\r\n",
        "test_data[num_cols] = trans.fit_transform(test_data[num_cols])\r\n",
        "\r\n",
        "## Remove features\r\n",
        "train_useless_features = train_data[['DI','RUL']]\r\n",
        "train_data = train_data.drop(['DI','RUL'],axis=1)\r\n",
        "\r\n",
        "train_RUL_I = train_data[\"RUL_I\"]\r\n",
        "train_data = train_data.drop(\"RUL_I\",axis=1)\r\n",
        "\r\n",
        "test_useless_features = test_data[['DI','RUL']]\r\n",
        "test_data = test_data.drop(['DI','RUL'],axis=1)\r\n",
        "\r\n",
        "test_RUL_I = test_data[\"RUL_I\"]\r\n",
        "test_data = test_data.drop(\"RUL_I\",axis=1)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPJk8aP6FaMo",
        "outputId": "88fc830f-26a7-44fc-8a2d-4a8d9045da0f"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "# split the dataset in evaluation and test set\r\n",
        "X_eva, X_test, Y_eva, Y_test = train_test_split(test_data, test_RUL_I, test_size=0.77, random_state=42)\r\n",
        "print(\"Number of samples for evaluation: %d, Number of features used: %d \" % (X_eva.shape[0], X_eva.shape[1])) \r\n",
        "print(\"Number of samples for testing: %d, Number of features used: %d \" % (X_test.shape[0], X_test.shape[1])) \r\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples for evaluation: 4799, Number of features used: 32 \n",
            "Number of samples for testing: 16068, Number of features used: 32 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24Fgc252Fpnk",
        "outputId": "21aa8ed6-d1a8-4b2f-ade8-8758ed744eab"
      },
      "source": [
        "from keras.layers import Dense\r\n",
        "# create a sequential model using tensor flow;\r\n",
        "# Another way, is a functional model.\r\n",
        "# add layers to the sequential model\r\n",
        "def baseline_model():\r\n",
        "  Telemetry_Vibration_NN = tf.keras.models.Sequential()\r\n",
        "\r\n",
        "\r\n",
        "  # Input Layer: feed it with a tensor of size (30,1)\r\n",
        "  Telemetry_Vibration_NN.add(Dense(32, input_dim = 32, kernel_initializer='normal', activation='relu' ))\r\n",
        "\r\n",
        "  # Hidden Layer : It is composed by 15 neurons\r\n",
        "  Telemetry_Vibration_NN.add(Dense(16, kernel_initializer='normal'))\r\n",
        "\r\n",
        "  # Output Layer: 2 neurons, each one computes a probability of a particular classe\r\n",
        "  # Telemetry_Vibration_NN.add(layers.Dense(1, activation = \"softmax\"))\r\n",
        "  Telemetry_Vibration_NN.add(Dense(1, kernel_initializer='normal'))\r\n",
        "\r\n",
        "\r\n",
        "  # display a summary of the model's topology and the parameters that need to be trained.\r\n",
        "  Telemetry_Vibration_NN.summary()\r\n",
        "\r\n",
        "  #Configure the model for training stage.\r\n",
        "  Telemetry_Vibration_NN.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\r\n",
        "return Telemetry_Vibration_NN\r\n",
        "\r\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_26 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,601\n",
            "Trainable params: 1,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhQ0OZe3HPXu"
      },
      "source": [
        "# Estimators\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\r\n",
        "\r\n",
        "#estimators = []\r\n",
        "#estimators.append(('standardize', StandardScaler()))\r\n",
        "\r\n",
        "# epochs - numero de interações\r\n",
        "#estimators.append(('mlp', KerasRegressor(build_fn=Telemetry_Vibration_NN, epochs=100, batch_size=5, verbose=0)))\r\n",
        "estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3HMf-heICgx",
        "outputId": "be853d2d-01e4-43eb-fc8b-ce38c743a7e1"
      },
      "source": [
        "# Pipeline\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "\r\n",
        "#pipeline = Pipeline(estimators)\r\n",
        "kfold = KFold(n_splits=2)\r\n",
        "\r\n",
        "# resultados \r\n",
        "results = cross_val_score(estimator, train_data, train_RUL_I, cv=kfold)\r\n",
        "print(\"Baseline: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline: nan (nan) MSE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: The first argument to `Layer.call` must always be passed.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}